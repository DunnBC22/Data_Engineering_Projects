{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "def generate_insert_statements(csv_file, database_name, table_name, create_table_stmt, output_file):\n",
    "    def parse_create_table(create_table_stmt):\n",
    "        # Extract the column definitions and types\n",
    "        columns = re.findall(r'(\\w+)\\s+(\\w+)', create_table_stmt, re.IGNORECASE)\n",
    "        column_names = [col[0] for col in columns]\n",
    "        column_types = {col[0]: col[1].upper() for col in columns}\n",
    "        return column_names, column_types\n",
    "    \n",
    "    # Parse the CREATE TABLE statement to get column names and types\n",
    "    column_names, column_types = parse_create_table(create_table_stmt)\n",
    "    \n",
    "    # Read the CSV file headers\n",
    "    with open(csv_file, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        csv_headers = reader.fieldnames\n",
    "    \n",
    "    # Ensure CSV headers match the column names in the CREATE TABLE statement\n",
    "    column_names = [col for col in column_names if col in csv_headers]\n",
    "    \n",
    "    # Read the CSV file and generate INSERT statements\n",
    "    insert_statements = []\n",
    "    with open(csv_file, newline='', encoding='utf-8') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader:\n",
    "            values = []\n",
    "            for col in column_names:\n",
    "                value = row[col]\n",
    "                if column_types[col] in ['FLOAT']:\n",
    "                    # Handle float values\n",
    "                    if value:\n",
    "                        values.append(value)\n",
    "                    else:\n",
    "                        values.append('NULL')\n",
    "                elif column_types[col] in ['TEXT', 'VARCHAR']:\n",
    "                    # Handle string values\n",
    "                    if value:\n",
    "                        values.append(f\"'{value}'\")\n",
    "                    else:\n",
    "                        values.append('NULL')\n",
    "                else:\n",
    "                    # Handle all other types as strings\n",
    "                    if value:\n",
    "                        values.append(f\"'{value}'\")\n",
    "                    else:\n",
    "                        values.append('NULL')\n",
    "            values_str = ', '.join(values)\n",
    "            insert_statements.append(f\"INSERT INTO {database_name}.{table_name} ({', '.join(column_names)}) VALUES ({values_str});\")\n",
    "    \n",
    "    # Write INSERT statements to the output file\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        for stmt in insert_statements:\n",
    "            f.write(stmt + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stream_statement = \"\"\"\n",
    "CREATE TABLE texas_ois_central (\n",
    "    dist VARCHAR,\n",
    "    district_edit VARCHAR,\n",
    "    date_called_in VARCHAR,\n",
    "    date_called_in_edit VARCHAR,\n",
    "    date_of_spill VARCHAR,\n",
    "    date_of_spill_edit VARCHAR,\n",
    "    spill_number VARCHAR,\n",
    "    rrc_job_number VARCHAR,\n",
    "    operator_rp VARCHAR,\n",
    "    operator_edit VARCHAR,\n",
    "    lease_facility_name VARCHAR,\n",
    "    rrc_id_number VARCHAR,\n",
    "    county VARCHAR,\n",
    "    county_edit VARCHAR,\n",
    "    type_operation VARCHAR,\n",
    "    source VARCHAR,\n",
    "    probable_cause VARCHAR,\n",
    "    probable_cause_edit VARCHAR,\n",
    "    release_crude_oil VARCHAR,\n",
    "    release_crude_oil_edit FLOAT,\n",
    "    release_cond VARCHAR,\n",
    "    release_prod_wtr VARCHAR,\n",
    "    release_prod_water_edit FLOAT,\n",
    "    release_gas VARCHAR,\n",
    "    recovery_crude_oil VARCHAR,\n",
    "    recovery_crude_oil_edit FLOAT,\n",
    "    recovery_cond VARCHAR,\n",
    "    recovery_prod_wtr VARCHAR,\n",
    "    recovery_prod_water_edit VARCHAR,\n",
    "    basis VARCHAR,\n",
    "    other_rptd_loss_type VARCHAR,\n",
    "    loss VARCHAR,\n",
    "    recovery_num FLOAT,\n",
    "    affected_area VARCHAR,\n",
    "    spill_on_water VARCHAR,\n",
    "    spill_on_water_edit VARCHAR,\n",
    "    ospra VARCHAR,\n",
    "    swr_ VARCHAR,\n",
    "    swr_9exempt VARCHAR,\n",
    "    cleanup_criteria_swr_91 VARCHAR,\n",
    "    cleanup_criteria_7_00_doc VARCHAR,\n",
    "    cleanup_criteria_case_specific VARCHAR,\n",
    "    form_h_rqrd VARCHAR,\n",
    "    form_h_rqrd_edit VARCHAR,\n",
    "    date_h_rcvd VARCHAR,\n",
    "    cleanup_oversight_district VARCHAR,\n",
    "    cleanup_oversight_austin VARCHAR,\n",
    "    status_or_phase VARCHAR,\n",
    "    comments TEXT,\n",
    "    compliance_date TEXT,\n",
    "    file_name VARCHAR,\n",
    "    sheet VARCHAR,\n",
    "    cleanup_criteria VARCHAR,\n",
    "    cleanup_oversight VARCHAR,\n",
    "    rrc_job_number_2 VARCHAR,\n",
    "    my_of_spill VARCHAR\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "database_name = 'texas_ois'\n",
    "\n",
    "input_data_file = '/Users/briandunn/Desktop/Kafka Connect/Texas Oil Industry Spills - CockroachDB to Many DBs/orig-data/central_cleaned.csv'\n",
    "\n",
    "output_file_location = '/Users/briandunn/Desktop/Kafka Connect/Texas Oil Industry Spills - CockroachDB to Many DBs/source-scripts/2_inserts_central.sql'\n",
    "\n",
    "generate_insert_statements(\n",
    "    input_data_file, \n",
    "    database_name, \n",
    "    \"texas_ois_central\",\n",
    "    create_stream_statement, \n",
    "    output_file_location\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stream_statement = \"\"\"\n",
    "CREATE TABLE texas_ois_district (\n",
    "    dist VARCHAR,\n",
    "    district_edit VARCHAR NOT NULL,\n",
    "    date_of_spill VARCHAR,\n",
    "    date_of_spill_edit VARCHAR,\n",
    "    date_called_in VARCHAR,\n",
    "    date_called_in_edit VARCHAR,\n",
    "    spill_number VARCHAR,\n",
    "    rrc_job_number VARCHAR,\n",
    "    operator_rp VARCHAR,\n",
    "    operator_edit VARCHAR,\n",
    "    lease_facility_name VARCHAR,\n",
    "    rrc_id_number VARCHAR,\n",
    "    county_name VARCHAR,\n",
    "    county_edited VARCHAR,\n",
    "    type_operation VARCHAR,\n",
    "    source VARCHAR,\n",
    "    probable_cause VARCHAR,\n",
    "    probable_cause_edit VARCHAR,\n",
    "    release_crude_oil VARCHAR,\n",
    "    release_crude_oil_edit VARCHAR,\n",
    "    release_cond VARCHAR,\n",
    "    release_prod_wtr VARCHAR,\n",
    "    release_prod_water_edit FLOAT,\n",
    "    release_gas VARCHAR,\n",
    "    recovery_crude_oil VARCHAR,\n",
    "    recovery_crude_oil_edit FLOAT,\n",
    "    recovery_cond VARCHAR,\n",
    "    recovery_prod_wtr VARCHAR,\n",
    "    recovery_prod_water_edit VARCHAR,\n",
    "    basis VARCHAR,\n",
    "    other_rptd_loss_type VARCHAR,\n",
    "    loss VARCHAR,\n",
    "    recovery_num VARCHAR,\n",
    "    affected_area VARCHAR,\n",
    "    spill_on_water VARCHAR,\n",
    "    spill_on_water_edit VARCHAR,\n",
    "    ospra VARCHAR,\n",
    "    swr_ VARCHAR,\n",
    "    swr_9exempt VARCHAR,\n",
    "    cleanup_criteria_swr_91 VARCHAR,\n",
    "    cleanup_criteria_7_00_doc VARCHAR,\n",
    "    cleanup_criteria_case_specific VARCHAR,\n",
    "    form_h_rqrd VARCHAR,\n",
    "    form_hrqrd_edit VARCHAR,\n",
    "    date_h_rcvd VARCHAR,\n",
    "    date_hrcvd_edit VARCHAR,\n",
    "    cleanup_oversight_district VARCHAR,\n",
    "    cleanup_oversight_austin VARCHAR,\n",
    "    status_or_phase VARCHAR,\n",
    "    comments TEXT,\n",
    "    compliance_date VARCHAR,\n",
    "    isocspill FLOAT,\n",
    "    ocinsp FLOAT,\n",
    "    ispwspill FLOAT,\n",
    "    pwinsp FLOAT,\n",
    "    isotherspill FLOAT,\n",
    "    otinsp FLOAT,\n",
    "    last_inspection_date VARCHAR,\n",
    "    cleanup_criteria VARCHAR,\n",
    "    cleanup_oversight VARCHAR,\n",
    "    notes TEXT,\n",
    "    inspection_id VARCHAR,\n",
    "    soil_water_samples_required VARCHAR,\n",
    "    spill_letter_date VARCHAR,\n",
    "    inspector VARCHAR,\n",
    "    witn_tech VARCHAR,\n",
    "    date_witnessed VARCHAR,\n",
    "    witn_results VARCHAR,\n",
    "    cleanup_method VARCHAR,\n",
    "    tph_rcvd VARCHAR,\n",
    "    tph_comments VARCHAR,\n",
    "    duplicate VARCHAR\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "database_name = 'texas_ois'\n",
    "\n",
    "input_data_file = '/Users/briandunn/Desktop/Kafka Connect/Texas Oil Industry Spills - CockroachDB to Many DBs/orig-data/district_cleaned.csv'\n",
    "\n",
    "output_file_location = '/Users/briandunn/Desktop/Kafka Connect/Texas Oil Industry Spills - CockroachDB to Many DBs/source-scripts/2_inserts_district.sql'\n",
    "\n",
    "generate_insert_statements(\n",
    "    input_data_file, \n",
    "    database_name,\n",
    "    \"texas_ois_district\", \n",
    "    create_stream_statement, \n",
    "    output_file_location\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
