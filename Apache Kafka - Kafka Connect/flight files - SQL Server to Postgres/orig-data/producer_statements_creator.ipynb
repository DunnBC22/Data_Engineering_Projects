{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv, re, os\n",
    "\n",
    "# def generate_insert_statements(\n",
    "#     csv_file, \n",
    "#     create_stream_statement, \n",
    "#     output_file, \n",
    "#     table_name,\n",
    "#     encoding='utf-8'\n",
    "# ):\n",
    "#     # Extract content within parentheses\n",
    "#     stream_content = re.search(r'\\((.*?)\\)', create_stream_statement, re.DOTALL).group(1)\n",
    "    \n",
    "#     # Split content into individual column definitions\n",
    "#     columns = re.findall(r'([a-zA-Z_]+)\\s+([a-zA-Z_]+)', stream_content)\n",
    "\n",
    "#     # Extract column names and data types\n",
    "#     column_names_create_stream = [col[0].strip() for col in columns]\n",
    "#     data_types_create_stream = {col[0].strip(): col[1] for col in columns}\n",
    "\n",
    "#     # Open the CSV file\n",
    "#     with open(csv_file, newline='', encoding=encoding, errors='ignore') as csvfile:\n",
    "#         reader = csv.DictReader(csvfile)\n",
    "#         insert_statements = []\n",
    "\n",
    "#         # Iterate over each row in the CSV\n",
    "#         for row in reader:\n",
    "#             columns = []\n",
    "#             values = []\n",
    "\n",
    "#             # Iterate over each column in the row\n",
    "#             for field, value in row.items():\n",
    "#                 # Include all columns from the CSV file in INSERT INTO statement\n",
    "#                 columns.append(field)\n",
    "#                 if value is None or value.strip() == \"\":\n",
    "#                     # Replace None values or empty strings with NULL\n",
    "#                     values.append(\"NULL\")\n",
    "#                 else:\n",
    "#                     # Handle non-empty values\n",
    "#                     data_type = data_types_create_stream.get(field)\n",
    "#                     if data_type == \"INTEGER\" or data_type == \"DOUBLE\" or data_type == \"FLOAT\":\n",
    "#                         # Handle numerical data types\n",
    "#                         values.append(value)\n",
    "#                     elif data_type == \"TIMESTAMP\" or data_type == \"DATE\":\n",
    "#                         # Handle timestamp and date data types\n",
    "#                         values.append(\"'\" + str(value) + \"'\")\n",
    "#                     else:\n",
    "#                         # Handle other data types as strings\n",
    "#                         values.append(\"'\" + str(value).replace(\"'\", \"''\") + \"'\")\n",
    "\n",
    "#             # Construct the INSERT INTO statement with the specified table name\n",
    "#             insert_statement = f\"INSERT INTO {table_name} ({','.join(columns)}) VALUES ({', '.join(values)});\"\n",
    "#             insert_statements.append(insert_statement)\n",
    "\n",
    "#     # Write insert statements to output file\n",
    "#     with open(output_file, 'w', encoding=encoding, errors='ignore') as f:\n",
    "#         for statement in insert_statements:\n",
    "#             f.write(statement + '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "def generate_insert_statements(\n",
    "    csv_file, \n",
    "    create_stream_statement, \n",
    "    output_file, \n",
    "    table_name,\n",
    "    encoding='utf-8'\n",
    "):\n",
    "    # Extract content within parentheses\n",
    "    stream_content = re.search(r'\\((.*?)\\)', create_stream_statement, re.DOTALL).group(1)\n",
    "    \n",
    "    # Split content into individual column definitions\n",
    "    columns = re.findall(r'([a-zA-Z_]+)\\s+([a-zA-Z_]+)', stream_content)\n",
    "\n",
    "    # Extract column names and data types\n",
    "    column_names_create_stream = [col[0].strip() for col in columns]\n",
    "    data_types_create_stream = {col[0].strip(): col[1] for col in columns}\n",
    "\n",
    "    # Open the CSV file\n",
    "    with open(csv_file, newline='', encoding=encoding, errors='ignore') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        insert_statements = []\n",
    "\n",
    "        # Iterate over each row in the CSV\n",
    "        for row in reader:\n",
    "            columns = []\n",
    "            values = []\n",
    "\n",
    "            # Iterate over each column in the row\n",
    "            for field, value in row.items():\n",
    "                # Include all columns from the CSV file in INSERT INTO statement\n",
    "                columns.append(field)\n",
    "                if value is None or value.strip() == \"\":\n",
    "                    # Replace None values or empty strings with NULL\n",
    "                    values.append(\"NULL\")\n",
    "                else:\n",
    "                    # Handle non-empty values\n",
    "                    data_type = data_types_create_stream.get(field)\n",
    "                    if data_type in [\"INTEGER\", \"BIGINT\", \"FLOAT\", \"REAL\"]:\n",
    "                        # Handle numerical data types\n",
    "                        values.append(value)\n",
    "                    elif data_type in [\"DATETIME\", \"DATE\", \"TIME\"]:\n",
    "                        # Handle date and time data types\n",
    "                        values.append(f\"'{value}'\")\n",
    "                    else:\n",
    "                        # Handle other data types as strings\n",
    "                        escaped_value = str(value).replace(\"'\", \"''\")\n",
    "                        values.append(f\"'{escaped_value}'\")\n",
    "\n",
    "            # Construct the INSERT INTO statement with the specified table name\n",
    "            insert_statement = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(values)});\"\n",
    "            insert_statements.append(insert_statement)\n",
    "\n",
    "    # Write insert statements to output file\n",
    "    with open(output_file, 'w', encoding=encoding, errors='ignore') as f:\n",
    "        for statement in insert_statements:\n",
    "            f.write(statement + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stream_statement = \"\"\"\n",
    "CREATE TABLE table_name_placeholder (\n",
    "\tflight_year INTEGER,\n",
    "\tflight_quarter INTEGER,\n",
    "\tflight_month INTEGER,\n",
    "\tflight_day_of_month INTEGER,\n",
    "\tflight_day_of_week INTEGER,\n",
    "\tflight_date VARCHAR,\n",
    "\tmarketing_airline_network VARCHAR,\n",
    "\toperated_or_branded_code_share_partners VARCHAR,\n",
    "\tdot_id_marketing_airline INTEGER,\n",
    "\tiata_code_marketing_airline VARCHAR,\n",
    "\tflight_number_marketing_airline INTEGER,\n",
    "\toriginally_scheduled_code_share_airline VARCHAR,\n",
    "\tdot_id_originally_scheduled_code_share_airline VARCHAR,\n",
    "\tiata_code_originally_scheduled_code_share_airline VARCHAR,\n",
    "\tflight_num_originally_scheduled_code_share_airline VARCHAR,\n",
    "\toperating_airline VARCHAR,\n",
    "\tdot_id_operating_airline INTEGER,\n",
    "\tiata_code_operating_airline VARCHAR,\n",
    "\tTail_number VARCHAR,\n",
    "\tflight_number_operating_airline INTEGER,\n",
    "\torigin_airport_id INTEGER,\n",
    "\torigin_airport_seq_id INTEGER,\n",
    "\torigin_city_market_id INTEGER,\n",
    "\torigin VARCHAR,\n",
    "\torigin_city_name VARCHAR,\n",
    "\torigin_state VARCHAR,\n",
    "\torigin_state_fips FLOAT,\n",
    "\torigin_state_name VARCHAR,\n",
    "\torigin_wac INTEGER,\n",
    "\tdest_airport_id INTEGER,\n",
    "\tdest_airport_seq_id INTEGER,\n",
    "\tdest_city_market_id INTEGER,\n",
    "\tdest VARCHAR,\n",
    "\tdest_city_name VARCHAR,\n",
    "\tdest_state VARCHAR,\n",
    "\tdest_state_fips INTEGER,\n",
    "\tdest_state_name VARCHAR,\n",
    "\tdest_wac INTEGER,\n",
    "\tcrs_dep_time INTEGER,\n",
    "\tdep_time INTEGER,\n",
    "\tdep_delay FLOAT,\n",
    "\tdep_delay_minutes FLOAT,\n",
    "\tdep_del_15 FLOAT,\n",
    "\tdeparture_delay_groups INTEGER,\n",
    "\tdep_time_blk VARCHAR,\n",
    "\ttaxi_out FLOAT,\n",
    "\twheels_off INTEGER,\n",
    "\twheels_on INTEGER,\n",
    "\ttaxi_in FLOAT,\n",
    "\tcrs_arr_time INTEGER,\n",
    "\tarr_time INTEGER,\n",
    "\tarr_delay FLOAT,\n",
    "\tarr_delay_minutes FLOAT,\n",
    "\tarr_del_15 FLOAT,\n",
    "\tarrival_delay_groups INTEGER,\n",
    "\tarr_time_blk VARCHAR,\n",
    "\tcancelled FLOAT,\n",
    "\tcancellation_code VARCHAR,\n",
    "\tdiverted FLOAT,\n",
    "\tcrse_lapsed_time FLOAT,\n",
    "\tactual_elapsed_time FLOAT,\n",
    "\tair_time FLOAT,\n",
    "\tflights FLOAT,\n",
    "\tdistance FLOAT,\n",
    "\tdistance_group INTEGER,\n",
    "\tcarrier_delay FLOAT,\n",
    "\tweather_delay FLOAT,\n",
    "\tnas_delay FLOAT,\n",
    "\tsecurity_delay FLOAT,\n",
    "\tlate_aircraft_delay FLOAT,\n",
    "\tfirst_dep_time INTEGER,\n",
    "\ttotal_add_g_time FLOAT,\n",
    "\tlongest_add_g_time FLOAT,\n",
    "\tdiv_airport_landings INTEGER,\n",
    "\tdiv_reached_dest VARCHAR,\n",
    "\tdiv_actual_elapsed_time VARCHAR,\n",
    "\tdiv_arr_delay VARCHAR,\n",
    "\tdiv_distance VARCHAR,\n",
    "\tdiv1_airport VARCHAR,\n",
    "\tdiv1_airport_id VARCHAR,\n",
    "\tdiv1_airport_seq_id VARCHAR,\n",
    "\tdiv1_wheels_on VARCHAR,\n",
    "\tdiv1_total_g_time VARCHAR,\n",
    "\tdiv1_longest_g_time VARCHAR,\n",
    "\tdiv1_wheels_off VARCHAR,\n",
    "\tdiv1_tail_num VARCHAR,\n",
    "\tdiv2_airport VARCHAR,\n",
    "\tdiv2_airport_id VARCHAR,\n",
    "\tdiv2_airport_seq_id VARCHAR,\n",
    "\tdiv2_wheels_on VARCHAR,\n",
    "\tdiv2_total_g_time VARCHAR,\n",
    "\tdiv2_longest_g_time VARCHAR,\n",
    "\tdiv2_wheels_off VARCHAR,\n",
    "\tdiv2_tail_num VARCHAR,\n",
    "\tdiv3_airport VARCHAR,\n",
    "\tdiv3_airport_id VARCHAR,\n",
    "\tdiv3_airport_seq_id VARCHAR,\n",
    "\tdiv3_wheels_on VARCHAR,\n",
    "\tdiv3_total_g_time VARCHAR,\n",
    "\tdiv3_longest_g_time VARCHAR,\n",
    "\tdiv3_wheels_off VARCHAR,\n",
    "\tdiv3_tail_num VARCHAR,\n",
    "\tdiv4_airport VARCHAR,\n",
    "\tdiv4_airport_id VARCHAR,\n",
    "\tdiv4_airport_seq_id VARCHAR,\n",
    "\tdiv4_wheels_on VARCHAR,\n",
    "\tdiv4_total_g_time VARCHAR,\n",
    "\tdiv4_longest_g_time VARCHAR,\n",
    "\tdiv4_wheels_off VARCHAR,\n",
    "\tdiv4_tail_num VARCHAR,\n",
    "\tdiv5_airport VARCHAR,\n",
    "\tdiv5_airport_id VARCHAR,\n",
    "\tdiv5_airport_seq_id VARCHAR,\n",
    "\tdiv5_wheels_on VARCHAR,\n",
    "\tdiv5_total_g_time VARCHAR,\n",
    "\tdiv5_longest_g_time VARCHAR,\n",
    "\tdiv5_wheels_off VARCHAR,\n",
    "\tdiv5_tail_num VARCHAR,\n",
    "\tduplicate VARCHAR)\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "input_data_folder = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect_non_postgres/flight files - SQL Server to Cassandra/orig-data'\n",
    "\n",
    "file_names = [\n",
    "    'Flights_2022_1', \n",
    "    'Flights_2022_2', \n",
    "    'Flights_2022_3', \n",
    "    'Flights_2022_4',\n",
    "    'Flights_2022_5', \n",
    "    'Flights_2022_6',\n",
    "    'Flights_2022_7'\n",
    "    ]\n",
    "\n",
    "output_folder_location = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect_non_postgres/flight files - SQL Server to Cassandra/sql-server-source-scripts'\n",
    "\n",
    "for file in file_names:\n",
    "    input_data_file = os.path.join(input_data_folder, file + '.csv')\n",
    "    output_file_location = os.path.join(output_folder_location, '3_schema_inserts_2022_' + file.split('_')[-1] + '.sql')\n",
    "    \n",
    "    generate_insert_statements(\n",
    "        input_data_file, \n",
    "        create_stream_statement, \n",
    "        output_file_location,\n",
    "        \"dbo.\" + file.lower()\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
