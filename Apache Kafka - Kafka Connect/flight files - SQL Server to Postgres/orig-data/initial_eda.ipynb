{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_location = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect_non_postgres/flight files with ElasticSearch/orig-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_csv_files(folder_path):\n",
    "    # Get list of all files in the folder\n",
    "    file_list = os.listdir(folder_path)\n",
    "    \n",
    "    # Filter out non-CSV files\n",
    "    csv_files = [file for file in file_list if file.endswith('.csv')]\n",
    "    \n",
    "    # Check if any CSV files found\n",
    "    if len(csv_files) == 0:\n",
    "        print(\"No CSV files found in the folder.\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize an empty list to store individual DataFrames\n",
    "    dfs = []\n",
    "    \n",
    "    # Read each CSV file and append its DataFrame to the list\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df = pd.read_csv(file_path, engine='c')\n",
    "        dfs.append(df)\n",
    "    \n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    concatenated_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    return concatenated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/93/v_c2ph_17t97zdkzc4_ccjtw0000gn/T/ipykernel_55285/708341397.py:19: DtypeWarning: Columns (11,13,78,85,86,93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/93/v_c2ph_17t97zdkzc4_ccjtw0000gn/T/ipykernel_55285/708341397.py:19: DtypeWarning: Columns (11,13,86,93,94) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/93/v_c2ph_17t97zdkzc4_ccjtw0000gn/T/ipykernel_55285/708341397.py:19: DtypeWarning: Columns (11,13,78,85,86,93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/93/v_c2ph_17t97zdkzc4_ccjtw0000gn/T/ipykernel_55285/708341397.py:19: DtypeWarning: Columns (11,13,86,93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/93/v_c2ph_17t97zdkzc4_ccjtw0000gn/T/ipykernel_55285/708341397.py:19: DtypeWarning: Columns (11,13,86,93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/93/v_c2ph_17t97zdkzc4_ccjtw0000gn/T/ipykernel_55285/708341397.py:19: DtypeWarning: Columns (11,13,86,93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/93/v_c2ph_17t97zdkzc4_ccjtw0000gn/T/ipykernel_55285/708341397.py:19: DtypeWarning: Columns (11,13,85,86,93) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4078318 entries, 0 to 4078317\n",
      "Columns: 119 entries, flight_year to  duplicate\n",
      "dtypes: float64(70), int64(23), object(26)\n",
      "memory usage: 3.6+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Path to the folder containing CSV files\n",
    "folder_path = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect_non_postgres/flight files with ElasticSearch/orig-data'\n",
    "\n",
    "# Call the function to concatenate CSV files\n",
    "df = concatenate_csv_files(folder_path)\n",
    "\n",
    "# Print the first few rows of the concatenated DataFrame\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4078318 entries, 0 to 4078317\n",
      "Columns: 119 entries, flight_year to  duplicate\n",
      "dtypes: float64(70), int64(23), object(26)\n",
      "memory usage: 3.6+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flight_year: 4\n",
      " flight_quarter: 1\n",
      " flight_month: 1\n",
      " flight_day_of_month: 2\n",
      " flight_day_of_week: 1\n",
      " flight_date: 10\n",
      " marketing_airline_network: 2\n",
      " operated_or_branded_code_share_partners: 12\n",
      " dot_id_marketing_airline: 5\n",
      " iata_code_marketing_airline: 2\n",
      " flight_number_marketing_airline: 4\n",
      " originally_scheduled_code_share_airline: 3\n",
      " dot_id_originally_scheduled_code_share_airline: 7\n",
      " iata_code_originally_scheduled_code_share_airline: 3\n",
      " flight_num_originally_scheduled_code_share_airline: 6\n",
      " operating_airline: 2\n",
      " dot_id_operating_airline: 5\n",
      " iata_code_operating_airline: 2\n",
      " Tail_number: 6\n",
      " flight_number_operating_airline: 4\n",
      " origin_airport_id: 5\n",
      " origin_airport_seq_id: 7\n",
      " origin_city_market_id: 5\n",
      " origin: 3\n",
      " origin_city_name: 34\n",
      " origin_state: 2\n",
      " origin_state_fips: 2\n",
      " origin_state_name: 46\n",
      " origin_wac: 2\n",
      " dest_airport_id: 5\n",
      " dest_airport_seq_id: 7\n",
      " dest_city_market_id: 5\n",
      " dest: 3\n",
      " dest_city_name: 34\n",
      " dest_state: 2\n",
      " dest_state_fips: 2\n",
      " dest_state_name: 46\n",
      " dest_wac: 2\n",
      " crs_dep_time: 4\n",
      " dep_time: 6\n",
      " dep_delay: 6\n",
      " dep_delay_minutes: 6\n",
      " dep_del_15: 3\n",
      " departure_delay_groups: 4\n",
      " dep_time_blk: 9\n",
      " taxi_out: 5\n",
      " wheels_off: 6\n",
      " wheels_on: 6\n",
      " taxi_in: 5\n",
      " crs_arr_time: 4\n",
      " arr_time: 6\n",
      " arr_delay: 6\n",
      " arr_delay_minutes: 6\n",
      " arr_del_15: 3\n",
      " arrival_delay_groups: 4\n",
      " arr_time_blk: 9\n",
      " cancelled: 3\n",
      " cancellation_code: 3\n",
      " diverted: 3\n",
      " crse_lapsed_time: 5\n",
      " actual_elapsed_time: 5\n",
      " air_time: 5\n",
      " flights: 3\n",
      " distance: 6\n",
      " distance_group: 2\n",
      " carrier_delay: 6\n",
      " weather_delay: 6\n",
      " nas_delay: 6\n",
      " security_delay: 6\n",
      " late_aircraft_delay: 6\n",
      " first_dep_time: 6\n",
      " total_add_g_time: 5\n",
      " longest_add_g_time: 5\n",
      " div_airport_landings: 1\n",
      " div_reached_dest_: 3\n",
      " div_actual_elapsed_time: 6\n",
      " div_arr_delay: 6\n",
      " div_distance: 6\n",
      " div1_airport: 3\n",
      " div1_airport_id: 7\n",
      " div1_airport_seq_id: 9\n",
      " div1_wheels_on: 6\n",
      " div1_total_g_time: 5\n",
      " div1_longest_g_time: 5\n",
      " div1_wheels_off: 6\n",
      " div1_tail_num: 6\n",
      " div2_airport: 3\n",
      " div2_airport_id: 7\n",
      " div2_airport_seq_id: 9\n",
      " div2_wheels_on: 6\n",
      " div2_total_g_time: 5\n",
      " div2_longest_g_time: 5\n",
      " div2_wheels_off: 6\n",
      " div2_tail_num: 6\n",
      " div3_airport: 3\n",
      " div3_airport_id: 7\n",
      " div3_airport_seq_id: 9\n",
      " div3_wheels_on: 6\n",
      " div3_total_g_time: 4\n",
      " div3_longest_g_time: 4\n",
      " div3_wheels_off: 3\n",
      " div3_tail_num: 3\n",
      " div4_airport: 3\n",
      " div4_airport_id: 3\n",
      " div4_airport_seq_id: 3\n",
      " div4_wheels_on: 3\n",
      " div4_total_g_time: 3\n",
      " div4_longest_g_time: 3\n",
      " div4_wheels_off: 3\n",
      " div4_tail_num: 3\n",
      " div5_airport: 3\n",
      " div5_airport_id: 3\n",
      " div5_airport_seq_id: 3\n",
      " div5_wheels_on: 3\n",
      " div5_total_g_time: 3\n",
      " div5_longest_g_time: 3\n",
      " div5_wheels_off: 3\n",
      " div5_tail_num: 3\n",
      " duplicate: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def longest_string_length(df):\n",
    "    # Convert each column to string datatype\n",
    "    df = df.astype(str)\n",
    "    \n",
    "    # Initialize a dictionary to store the longest string length for each column\n",
    "    longest_lengths = {}\n",
    "    \n",
    "    # Iterate over each column\n",
    "    for column in df.columns:\n",
    "        # Find the maximum length of strings in the column\n",
    "        max_length = df[column].str.len().max()\n",
    "        longest_lengths[column] = max_length\n",
    "    \n",
    "    return longest_lengths\n",
    "\n",
    "# Example usage:\n",
    "\n",
    "lengths = longest_string_length(df)\n",
    "\n",
    "for column, length in lengths.items():\n",
    "    print(f\"{column}: {length}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
