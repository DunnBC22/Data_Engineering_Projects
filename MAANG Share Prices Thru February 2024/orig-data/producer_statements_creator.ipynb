{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "\n",
    "def generate_insert_statements(\n",
    "    csv_file, \n",
    "    create_stream_statement, \n",
    "    output_file, \n",
    "    table_name,\n",
    "    encoding='utf-8'\n",
    "):\n",
    "    # Extract content within parentheses\n",
    "    stream_content = re.search(r'\\((.*?)\\)', create_stream_statement, re.DOTALL).group(1)\n",
    "    \n",
    "    # Split content into individual column definitions\n",
    "    columns = re.findall(r'([a-zA-Z_]+)\\s+([a-zA-Z_]+)', stream_content)\n",
    "\n",
    "    # Extract column names and data types, stripping BOM if present\n",
    "    column_names_create_stream = [col[0].strip() for col in columns]\n",
    "    data_types_create_stream = {col[0].strip(): col[1] for col in columns}\n",
    "\n",
    "    # Open the CSV file\n",
    "    with open(csv_file, newline='', encoding=encoding, errors='ignore') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        insert_statements = []\n",
    "\n",
    "        # Iterate over each row in the CSV\n",
    "        for row in reader:\n",
    "            columns = []\n",
    "            values = []\n",
    "\n",
    "            # Iterate over each column in the row\n",
    "            for field, value in row.items():\n",
    "                if field in column_names_create_stream:\n",
    "                    # Column name exists in create_stream_statement\n",
    "                    data_type = data_types_create_stream[field]\n",
    "                    if value is None:\n",
    "                        columns.append(field)\n",
    "                        values.append(\"\")\n",
    "                    else:\n",
    "                        if data_type == \"DOUBLE\" or data_type == \"FLOAT\" or data_type == \"INTEGER\":\n",
    "                            value_str = str(value)\n",
    "                            if value_str.strip() == \"\":\n",
    "                                columns.append(field)\n",
    "                                values.append(\"\")\n",
    "                            else:\n",
    "                                columns.append(field)\n",
    "                                values.append(value_str)\n",
    "                        elif data_type == \"TIMESTAMP\" or data_type == \"DATE\":\n",
    "                            columns.append(field)\n",
    "                            values.append(\"'\" + str(value) + \"'\")\n",
    "                        elif data_type == \"VARCHAR\":\n",
    "                            columns.append(field)\n",
    "                            values.append(\"'\" + value.replace(\"'\", \"''\") + \"'\")\n",
    "                        # Handle other data types as needed\n",
    "\n",
    "            # Construct the INSERT INTO statement with the specified table name\n",
    "            insert_statement = f\"INSERT INTO {table_name} ({', '.join(columns)}) VALUES ({', '.join(values)});\"\n",
    "            insert_statements.append(insert_statement)\n",
    "\n",
    "    # Write insert statements to output file\n",
    "    with open(output_file, 'w', encoding=encoding, errors='ignore') as f:\n",
    "        for statement in insert_statements:\n",
    "            f.write(statement + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stream_statement = \"\"\"\n",
    "CREATE TABLE maang_source_amazon (\n",
    "    id INTEGER,\n",
    "    trading_date VARCHAR,\n",
    "    trading_open DOUBLE,\n",
    "    trading_high DOUBLE,\n",
    "    trading_low DOUBLE,\n",
    "    trading_close DOUBLE,\n",
    "    trading_adj_close DOUBLE,\n",
    "    trading_volume DOUBLE\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "input_data_file = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect/MAANG Share Prices Thru February 2024/orig-data/amazon.csv'\n",
    "\n",
    "output_file_location = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect/MAANG Share Prices Thru February 2024/statements/inserts/amazon_inserts.sql'\n",
    "\n",
    "generate_insert_statements(\n",
    "    input_data_file, \n",
    "    create_stream_statement, \n",
    "    output_file_location,\n",
    "    \"maang_source_amazon\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stream_statement = \"\"\"\n",
    "CREATE TABLE maang_source_apple (\n",
    "    id INTEGER,\n",
    "    trading_date VARCHAR,\n",
    "    trading_open DOUBLE,\n",
    "    trading_high DOUBLE,\n",
    "    trading_low DOUBLE,\n",
    "    trading_close DOUBLE,\n",
    "    trading_adj_close DOUBLE,\n",
    "    trading_volume DOUBLE\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "input_data_file = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect/MAANG Share Prices Thru February 2024/orig-data/apple.csv'\n",
    "\n",
    "output_file_location = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect/MAANG Share Prices Thru February 2024/statements/inserts/apple_inserts.sql'\n",
    "\n",
    "generate_insert_statements(\n",
    "    input_data_file, \n",
    "    create_stream_statement, \n",
    "    output_file_location,\n",
    "    \"maang_source_apple\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stream_statement = \"\"\"\n",
    "CREATE TABLE maang_source_google (\n",
    "    id INTEGER,\n",
    "    trading_date VARCHAR,\n",
    "    trading_open DOUBLE,\n",
    "    trading_high DOUBLE,\n",
    "    trading_low DOUBLE,\n",
    "    trading_close DOUBLE,\n",
    "    trading_adj_close DOUBLE,\n",
    "    trading_volume DOUBLE\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "input_data_file = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect/MAANG Share Prices Thru February 2024/orig-data/google.csv'\n",
    "\n",
    "output_file_location = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect/MAANG Share Prices Thru February 2024/statements/inserts/google_inserts.sql'\n",
    "\n",
    "generate_insert_statements(\n",
    "    input_data_file, \n",
    "    create_stream_statement, \n",
    "    output_file_location,\n",
    "    \"maang_source_google\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stream_statement = \"\"\"\n",
    "CREATE TABLE maang_source_meta (\n",
    "    id INTEGER,\n",
    "    trading_date VARCHAR,\n",
    "    trading_open DOUBLE,\n",
    "    trading_high DOUBLE,\n",
    "    trading_low DOUBLE,\n",
    "    trading_close DOUBLE,\n",
    "    trading_adj_close DOUBLE,\n",
    "    trading_volume DOUBLE\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "input_data_file = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect/MAANG Share Prices Thru February 2024/orig-data/meta.csv'\n",
    "\n",
    "output_file_location = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect/MAANG Share Prices Thru February 2024/statements/inserts/meta_inserts.sql'\n",
    "\n",
    "generate_insert_statements(\n",
    "    input_data_file, \n",
    "    create_stream_statement, \n",
    "    output_file_location,\n",
    "    \"maang_source_meta\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stream_statement = \"\"\"\n",
    "CREATE TABLE maang_source_netflix (\n",
    "    id INTEGER,\n",
    "    trading_date VARCHAR,\n",
    "    trading_open DOUBLE,\n",
    "    trading_high DOUBLE,\n",
    "    trading_low DOUBLE,\n",
    "    trading_close DOUBLE,\n",
    "    trading_adj_close DOUBLE,\n",
    "    trading_volume DOUBLE\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "input_data_file = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect/MAANG Share Prices Thru February 2024/orig-data/netflix.csv'\n",
    "\n",
    "output_file_location = '/Users/briandunn/Desktop/Apache_Kafka-Kafka_Connect/MAANG Share Prices Thru February 2024/statements/inserts/netflix_inserts.sql'\n",
    "\n",
    "generate_insert_statements(\n",
    "    input_data_file, \n",
    "    create_stream_statement, \n",
    "    output_file_location,\n",
    "    \"maang_source_netflix\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
